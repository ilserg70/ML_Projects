{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDC Lens Distortion Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install opencv-python\n",
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFrames(path_to_video, path_to_frames): \n",
    "    vidObj = cv2.VideoCapture(path_to_video) \n",
    "    count, success = 0, 1\n",
    "    while success: \n",
    "        success, image = vidObj.read() \n",
    "        cv2.imwrite(path_to_frames + \"/frame%d.jpg\" % count, image) \n",
    "        count += 1\n",
    "    print(f\"Count of frames: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../../mydata/evidences/5d952e0f-51fe-e1f2-a0aa-551938968072\" \n",
    "video_file = path_to_data + \"/video.mp4\"\n",
    "path_to_frames = path_to_data + \"/frames\"\n",
    "extractFrames(video_file, path_to_frames) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1\n",
    "https://hackaday.io/project/12384-autofan-automated-control-of-air-flow/log/41862-correcting-for-lens-distortions\n",
    "\n",
    "https://docs.opencv.org/2.4/doc/tutorials/calib3d/camera_calibration/camera_calibration.html\n",
    "\n",
    "This so-called barrel distortion results in the fact that the representation of distance relations in the real world is not the same as in the camera image -- i.e. distance relations in the camera image are non-linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lens_distortion_correction(K, d, img_file):\n",
    "    \"\"\"\n",
    "    K - camera matrix\n",
    "    d - distortion coefficients\n",
    "    img_file - path to img\n",
    "    \n",
    "    return (img, newimg)\n",
    "    \"\"\"\n",
    "\n",
    "    img = cv2.imread(img_file)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Generate new camera matrix from parameters\n",
    "    newcameramatrix, roi = cv2.getOptimalNewCameraMatrix(K, d, (w,h), 0)\n",
    "\n",
    "    # Generate look-up tables for remapping the camera image\n",
    "    mapx, mapy = cv2.initUndistortRectifyMap(K, d, None, newcameramatrix, (w, h), 5)\n",
    "\n",
    "    # Remap the original image to a new image\n",
    "    newimg = cv2.remap(img, mapx, mapy, cv2.INTER_LINEAR)\n",
    "    \n",
    "    return img, newimg\n",
    "\n",
    "def display_images(img, newimg):\n",
    "    fig, (oldimg_ax, newimg_ax) = plt.subplots(1, 2)\n",
    "    oldimg_ax.imshow(img)\n",
    "    oldimg_ax.set_title('Original image')\n",
    "    newimg_ax.imshow(newimg)\n",
    "    newimg_ax.set_title('Unwarped image')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define camera matrix K\n",
    "K = np.array([[673.9683892, 0., 343.68638231],\n",
    "              [0., 676.08466459, 245.31865398],\n",
    "              [0., 0., 1.]])\n",
    "\n",
    "# Define distortion coefficients d\n",
    "d = np.array([5.44787247e-02, 1.23043244e-01, -4.52559581e-04, 5.47011732e-03, -6.83110234e-01])\n",
    "\n",
    "img_file = path_to_frames + \"/frame30.jpg\"\n",
    "img, newimg = lens_distortion_correction(K, d, img_file)\n",
    "display_images(img, newimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python calibrate.py \"frames/frame30.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera calibration\n",
    "https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_calibration/py_calibration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = '/Users/silinskiy/mydata/chess_board/5de94dd1-963e-934c-5be5-551938968072'\n",
    "dir_inp = os.path.join(dir_data, 'frames')\n",
    "dir_out = os.path.join(dir_data, 'frames_corrected')\n",
    "dir_corners = None # os.path.join(dir_data, 'frames_corners')\n",
    "\n",
    "for d in [dir_out, dir_corners]:\n",
    "    if d and not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "\n",
    "img = cv2.imread(os.path.join(dir_inp, os.listdir(dir_inp)[0]))\n",
    "h,  w = img.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_chess_board_corners(img, criteria, vertical_points, horizont_points):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (vertical_points, horizont_points), None)\n",
    "    return cv2.cornerSubPix(gray,corners,(11,11),(-1,-1), criteria) if ret else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizont_points = 7\n",
    "vertical_points = 7\n",
    "\n",
    "frame_number_min = 0\n",
    "frame_number_max = 1244\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((horizont_points*vertical_points,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:vertical_points,0:horizont_points].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "for n in range(frame_number_min,frame_number_max+1):\n",
    "    file = f'frame{n}.jpg'\n",
    "    img = cv2.imread(os.path.join(dir_inp, file))\n",
    "    \n",
    "    corners = find_the_chess_board_corners(img, criteria, vertical_points, horizont_points)\n",
    "    if corners is not None:\n",
    "        print(file)\n",
    "        imgpoints.append(corners)\n",
    "        objpoints.append(objp)\n",
    "        \n",
    "        # Draw corners and save image to file\n",
    "        if dir_corners:\n",
    "            img2 = cv2.drawChessboardCorners(img, (vertical_points,horizont_points), corners, True)\n",
    "            cv2.imwrite(os.path.join(dir_corners, file), img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration\n",
    "camera matrix, distortion coefficients, rotation and translation vectors etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (w, h), None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undistortion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Using cv2.undistort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undistort\n",
    "file = 'frame555.jpg'\n",
    "img = cv2.imread(os.path.join(dir_inp, file))\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite(os.path.join(dir_out, file), dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Using remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undistort\n",
    "mapx,mapy = cv2.initUndistortRectifyMap(mtx,dist,None,newcameramtx,(w,h),5)\n",
    "dst = cv2.remap(img,mapx,mapy,cv2.INTER_LINEAR)\n",
    "\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite('calibresult.png',dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-projection Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = 0\n",
    "for i in xrange(len(objpoints)):\n",
    "    imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv2.norm(imgpoints[i],imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "    tot_error += error\n",
    "\n",
    "print \"total error: \", mean_error/len(objpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def calc_calibration_matrix(path_to_video, max_image_count = 50, horizont_points = 7, vertical_points = 7):\n",
    "    videoInp = cv2.VideoCapture(path_to_video)\n",
    "    w = int(videoInp.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(videoInp.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(f'video: width = {w} x height = {h}')\n",
    "    \n",
    "    # termination criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    \n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((horizont_points*vertical_points,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:vertical_points,0:horizont_points].T.reshape(-1,2)\n",
    "    \n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d point in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "    \n",
    "    count = 0\n",
    "    ok, img = videoInp.read()\n",
    "#     h,  w = img.shape[:2]\n",
    "    while ok and count < max_image_count:\n",
    "        corners = find_the_chess_board_corners(img, criteria, vertical_points, horizont_points)\n",
    "        if corners is not None:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            count += 1\n",
    "        ok, img = videoInp.read()\n",
    "    videoInp.release()\n",
    "    if count > 0:\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (w, h), None, None)\n",
    "        newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))\n",
    "        return (mtx, dist, newcameramtx)\n",
    "\n",
    "def calibrate_video(path_to_video, path_to_otput_video, mtx, dist, newcameramtx):\n",
    "    videoInp = cv2.VideoCapture(path_to_video)\n",
    "    w = int(videoInp.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(videoInp.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = 30\n",
    "    videoOut = cv2.VideoWriter(path_to_otput_video, cv2.VideoWriter_fourcc(*'H264'), fps, (w, h))\n",
    "    \n",
    "    ok, img = videoInp.read()\n",
    "    h,  w = img.shape[:2]\n",
    "    while ok:\n",
    "        img2 = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "        videoOut.write(img2)\n",
    "        ok, img = videoInp.read()\n",
    "    videoInp.release()\n",
    "    videoOut.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_video = os.path.join(dir_data, 'video.mp4')\n",
    "mtx, dist, newcameramtx = calc_calibration_matrix(path_to_video, max_image_count = 20)\n",
    "path_to_otput_video = os.path.join(dir_data, 'video_calibrated.mp4')\n",
    "#calibrate_video(path_to_video, path_to_otput_video, mtx, dist, newcameramtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/Users/silinskiy/axon_git/monitor-detection-tracking/mdt/detector/\")\n",
    "from transform import Transform\n",
    "T = Transform()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
