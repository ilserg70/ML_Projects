{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection and tracking objects across the frames (video => video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from yolo3_torch.lib import *\n",
    "model_data = 'yolo3_torch/model_data'\n",
    "\n",
    "model_params = {\n",
    "    'fileConfig': f'{model_data}/yolov3.cfg',\n",
    "    'fileYolo3Weights': f'{model_data}/yolov3.weights',\n",
    "    'fileClasses': f'{model_data}/object.classes',\n",
    "    'filePallete': f'{model_data}/pallete',\n",
    "    'inpDim': 416,\n",
    "    'confidence': 0.5,\n",
    "    'nmsThresh': 0.4,\n",
    "    'cachSize': 7,\n",
    "    'fps': 30\n",
    "}\n",
    "\n",
    "classes = load_classes(model_params['fileClasses'])\n",
    "model_params['numClasses'] = len(classes)\n",
    "\n",
    "def detect_objects_with_yolo3(frameId, frame, model, CUDA, model_params):\n",
    "    frameInp = image_to_model_input(frame, model_params['inpDim'])\n",
    "    \n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        pred = model(Variable(frameInp), CUDA)\n",
    "    end = time.time()\n",
    "    print(\"Frame: {0:6d} predicted in {1:6.3f} seconds\".format(int(frameId), end - start))\n",
    "\n",
    "    res = get_results(\n",
    "        prediction = pred,\n",
    "        confidence = model_params.get('confidence', 0.5), \n",
    "        numClasses = model_params['numClasses'],\n",
    "        nmsConf = model_params.get('nmsThresh', 0.4))\n",
    "    \n",
    "    if res is not None:\n",
    "        res = rescaling_to_original(res, (frame.shape[1], frame.shape[0]), model_params['inpDim'])\n",
    "        res[:,0] += frameId\n",
    "        res = add_column_for_object_id(res)\n",
    "\n",
    "    return res\n",
    "\n",
    "def annotation(data_params, model_params):\n",
    "\n",
    "    CUDA = torch.cuda.is_available()\n",
    "    print(\"CUDA is {} available.\".format(\"\" if CUDA else \"NOT\"))\n",
    "    model = upload_model(model_params['fileConfig'], model_params['fileYolo3Weights'], model_params['inpDim'], CUDA)\n",
    "    print(\"Model is loaded.\")\n",
    "    \n",
    "    results = None\n",
    "    \n",
    "    frameId = 0.\n",
    "    setObjId(0.)\n",
    "\n",
    "    fps = model_params.get('fps',30)\n",
    "\n",
    "    fileOut = data_params.get('fileDataOut', None)\n",
    "    colors = None if fileOut is None else pkl.load(open(model_params['filePallete'], \"rb\"))\n",
    "    name_len = data_params.get('name_len', None)\n",
    "\n",
    "    fileInp = data_params['fileDataInp']\n",
    "\n",
    "    if fileInp.endswith('.jpg'):\n",
    "        frame = cv2.imread(fileInp)\n",
    "        results = detect_objects_with_yolo3(frameId, frame, model, CUDA, model_params)\n",
    "        if results is not None:\n",
    "            fw, fh = frame.shape[1], frame.shape[0]\n",
    "            tracking_params = get_params(fps, fw, fh)\n",
    "            self_match_frame(results, tracking_params)\n",
    "            print(logging_classes(frameId, results, classes))\n",
    "            if fileOut is not None:\n",
    "                for obj in results:\n",
    "                    mark_one_object(frame, obj, colors, classes, name_len)\n",
    "                cv2.imwrite(fileOut, frame)\n",
    "\n",
    "    elif fileInp.endswith('.mp4'):\n",
    "        videoInp = cv2.VideoCapture(fileInp)\n",
    "        fw = int(videoInp.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        fh = int(videoInp.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        tracking_params = get_params(fps, fw, fh)\n",
    "        cachSize = model_params.get('cachSize', 7)\n",
    "\n",
    "        videoOut = None if fileOut is None else cv2.VideoWriter(fileOut, cv2.VideoWriter_fourcc(*'H264'), fps, (fw, fh))\n",
    "\n",
    "        dirDetected = data_params.get('dirDetected', None)\n",
    "        clean_and_mk_dir(dirDetected)\n",
    "        dirFrames = data_params.get('dirFrames', None)\n",
    "        clean_and_mk_dir(dirFrames)\n",
    "\n",
    "        startId = int(fps * float(data_params.get('startSecond', 0.)))\n",
    "        endId = int(startId -1 + fps * float(data_params.get('durationSeconds', 0.)))\n",
    "\n",
    "        cachFrm = []\n",
    "\n",
    "        start0 = time.time()\n",
    "\n",
    "        while True:\n",
    "            ok, frame = videoInp.read()\n",
    "            if not ok: \n",
    "                break\n",
    "            if frameId < startId:\n",
    "                frameId += 1\n",
    "                continue\n",
    "\n",
    "            res = detect_objects_with_yolo3(frameId, frame, model, CUDA, model_params)\n",
    "            if res is None:\n",
    "                frameId += 1\n",
    "                continue\n",
    "\n",
    "            print(logging_classes(frameId, res, classes))\n",
    "\n",
    "            results = res if results is None else torch.cat((results, res))\n",
    "            cachFrm.append((frameId,frame,res))\n",
    "\n",
    "\n",
    "            if len(cachFrm) > cachSize:\n",
    "                frameId_, frame_, _ = cachFrm.pop(0)\n",
    "                # Mark objects and save to output (video/dir).\n",
    "                if videoOut is not None:\n",
    "                    visualize_objects(frameId_, frame_, results, videoOut, colors, classes, dirFrames, dirDetected, name_len)\n",
    "\n",
    "            # Tracking objects across frames.\n",
    "            find_matches(cachFrm, tracking_params, results)\n",
    "            results = restore_miss_detection(cachFrm, results)\n",
    "\n",
    "            frameId += 1\n",
    "            if startId <= endId and frameId > endId:\n",
    "                break\n",
    "\n",
    "        while cachFrm:\n",
    "            frameId_, frame_, _ = cachFrm.pop(0)\n",
    "            if videoOut is not None:\n",
    "                # Mark objects and save to output (video/dir).\n",
    "                visualize_objects(frameId_, frame_, results, videoOut, colors, classes, dirFrames, dirDetected, name_len)\n",
    "\n",
    "        print(\"Aver. calc.: {0} sec.\".format((time.time()-start0)/(frameId-1)))\n",
    "\n",
    "        videoInp.release()\n",
    "        if videoOut is not None:\n",
    "            videoOut.release()\n",
    "\n",
    "    # if results is not None:\n",
    "    #     torch.save(results, fileTracked)        \n",
    "    print(\"Done.\")\n",
    "    # results: [frameId, xmin, ymin, xmax, ymax, conf., conf., objId, objClassId]\n",
    "    return results\n",
    "\n",
    "def convert_to_detected_objects(results):\n",
    "    return [{\n",
    "        'frameId': int(r[0]),\n",
    "        'xmin': int(r[1]),\n",
    "        'ymin': int(r[2]),\n",
    "        'xmax': int(r[3]),\n",
    "        'ymax': int(r[4]),\n",
    "        'conf1': float(r[5]),\n",
    "        'conf2': float(r[6]),\n",
    "        'objId': int(r[7]),\n",
    "        'class': classes[int(r[8])]\n",
    "    } for r in results] if results is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download from Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] UM0hX7nomi8: Downloading webpage\n",
      "[youtube] UM0hX7nomi8: Downloading video info webpage\n",
      "[download] tmp/UM0hX7nomi8.mp4 has already been downloaded and merged\n",
      "file: tmp/UM0hX7nomi8.mp4\n"
     ]
    }
   ],
   "source": [
    "url = 'https://youtu.be/UM0hX7nomi8'\n",
    "file = download_from_youtube(url, 'tmp')\n",
    "print(\"file: {}\".format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is NOT available.\n",
      "Model is loaded.\n",
      "Frame:      0 predicted in  0.929 seconds\n",
      "Frame:      0 Detected: car, car, car, car, car, car\n",
      "Frame:      1 predicted in  0.916 seconds\n",
      "Frame:      1 Detected: car, car, car, car, car, car\n",
      "Frame:      2 predicted in  0.923 seconds\n",
      "Frame:      2 Detected: car, car, car, car, car, car\n",
      "Frame:      3 predicted in  0.880 seconds\n",
      "Frame:      3 Detected: car, car, car, car, car, car, truck\n",
      "Frame:      4 predicted in  0.845 seconds\n",
      "Frame:      4 Detected: car, car, car, car, car, car\n",
      "Frame:      5 predicted in  0.848 seconds\n",
      "Frame:      5 Detected: car, car, car, car, car, car\n",
      "Frame:      6 predicted in  0.846 seconds\n",
      "Frame:      6 Detected: car, car, car, car, car, car\n",
      "Frame:      7 predicted in  0.857 seconds\n",
      "Frame:      7 Detected: car, car, car, car, car, car\n",
      "Frame:      8 predicted in  0.876 seconds\n",
      "Frame:      8 Detected: car, car, car, car, car, car, car\n",
      "Frame:      9 predicted in  0.972 seconds\n",
      "Frame:      9 Detected: car, car, car, car, car, car, car\n",
      "Frame:     10 predicted in  0.936 seconds\n",
      "Frame:     10 Detected: car, car, car, car, car, car, car\n",
      "Frame:     11 predicted in  0.846 seconds\n",
      "Frame:     11 Detected: car, car, car, car, car, car, car\n",
      "Frame:     12 predicted in  0.848 seconds\n",
      "Frame:     12 Detected: car, car, car, car, car, car, car, truck\n",
      "Frame:     13 predicted in  0.852 seconds\n",
      "Frame:     13 Detected: car, car, car, car, car, car, car\n",
      "Frame:     14 predicted in  0.870 seconds\n",
      "Frame:     14 Detected: car, car, car, car, car, car, car\n",
      "Frame:     15 predicted in  0.895 seconds\n",
      "Frame:     15 Detected: car, car, car, car, car, car, car\n",
      "Frame:     16 predicted in  0.901 seconds\n",
      "Frame:     16 Detected: car, car, car, car, car, car, car\n",
      "Frame:     17 predicted in  0.886 seconds\n",
      "Frame:     17 Detected: car, car, car, car, car, car, car\n",
      "Frame:     18 predicted in  0.894 seconds\n",
      "Frame:     18 Detected: car, car, car, car, car, car, car\n",
      "Frame:     19 predicted in  0.931 seconds\n",
      "Frame:     19 Detected: car, car, car, car, car, car\n",
      "Frame:     20 predicted in  0.883 seconds\n",
      "Frame:     20 Detected: car, car, car, car, car, car\n",
      "Frame:     21 predicted in  0.854 seconds\n",
      "Frame:     21 Detected: car, car, car, car, car, car\n",
      "Frame:     22 predicted in  0.848 seconds\n",
      "Frame:     22 Detected: car, car, car, car, car, car, truck\n",
      "Frame:     23 predicted in  0.844 seconds\n",
      "Frame:     23 Detected: car, car, car, car, car, car\n",
      "Frame:     24 predicted in  0.882 seconds\n",
      "Frame:     24 Detected: car, car, car, car, car, car, truck\n",
      "Frame:     25 predicted in  0.934 seconds\n",
      "Frame:     25 Detected: car, car, car, car, car\n",
      "Frame:     26 predicted in  0.860 seconds\n",
      "Frame:     26 Detected: car, car, car, car, car\n",
      "Frame:     27 predicted in  0.866 seconds\n",
      "Frame:     27 Detected: car, car, car, car, car\n",
      "Frame:     28 predicted in  0.842 seconds\n",
      "Frame:     28 Detected: car, car, car, car, car\n",
      "Frame:     29 predicted in  0.837 seconds\n",
      "Frame:     29 Detected: car, car, car, car, car\n",
      "Aver. calc.: 1.0358642134173164 sec.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "data_params = {\n",
    "    'fileDataInp': file,\n",
    "    'fileDataOut': add_suffix(file, '_detect'),\n",
    "    'dirFrames': 'tmp/{}_frames'.format(get_name(file)),\n",
    "    'dirDetected':  'tmp/{}_detect'.format(get_name(file)),\n",
    "    'name_len': None, # length of object class name to show on marked frame,\n",
    "    'startSecond': 0,\n",
    "    'durationSeconds': 1\n",
    "}\n",
    "\n",
    "results = annotation(data_params, model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://nails.newsela.com/s3/newsela-media/article_media/2017/10/self-driving-cars-nyc-6abce23d.jpg?crop=0%2C128%2C1366%2C896&height=497&horizontal_focal_point=center&vertical_focal_point=center&width=885\"\n",
    "frame = download_image(url)\n",
    "fileOut = 'tmp/test.jpg'\n",
    "cv2.imwrite(fileOut, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = {\n",
    "    'fileDataInp': 'tmp/test.jpg',\n",
    "    'fileDataOut': 'tmp/test_detect.jpg'\n",
    "}\n",
    "\n",
    "results2 = annotation(data_params, model_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
